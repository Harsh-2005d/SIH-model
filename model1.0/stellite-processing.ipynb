{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c44ce390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e096505d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# open your stacked GeoTIFF\n",
    "with rasterio.open(\"./data/satellite/sentinel/Delhi_NO2_2022_MM.tif\") as src:\n",
    "    NO2_2022=src.read()  # read all raster values\n",
    "\n",
    "with rasterio.open(\"./data/satellite/sentinel/Delhi_NO2_2023_MM.tif\") as src:\n",
    "    NO2_2023=src.read()  # read all raster values\n",
    "\n",
    "with rasterio.open(\"./data/satellite/sentinel/Delhi_o3_2022_MM.tif\") as src:\n",
    "    O3_2022=src.read()  # read all raster values\n",
    "\n",
    "with rasterio.open(\"./data/satellite/sentinel/Delhi_o3_2023_MM.tif\") as src:\n",
    "    O3_2023=src.read()\n",
    "\n",
    "with rasterio.open(\"./data/satellite/sentinel/Delhi_o3_2024_Tropospheric_Stack_MM.tif\") as src:\n",
    "    o3_2024=src.read()\n",
    "\n",
    "with rasterio.open(\"./data/satellite/sentinel/Delhi_NO2_2024_Tropospheric_Stack_MM.tif\") as src:\n",
    "    no2_2024=src.read()  # read all raster values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4fcce034",
   "metadata": {},
   "outputs": [],
   "source": [
    "no2=np.concat([NO2_2022,NO2_2023])\n",
    "o3=np.concat([O3_2022,O3_2023])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8284a8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputation(arr):\n",
    "    first_day=arr[0,:,:]\n",
    "    mean=np.nanmean(first_day)\n",
    "    missing=np.isnan(first_day)\n",
    "    first_day[missing]=mean\n",
    "\n",
    "    for day in range(1,arr.shape[0]):\n",
    "        elem=arr[day,:,:]\n",
    "        missing=np.isnan(elem)\n",
    "        prev=arr[day-1,:,:]\n",
    "        elem[missing]=prev[missing]\n",
    "\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "aaa02da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "no2=imputation(no2)\n",
    "o3=imputation(o3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3552ec19",
   "metadata": {},
   "outputs": [],
   "source": [
    "no2_2024=imputation(no2_2024)\n",
    "o3_2024=imputation(o3_2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "186f039d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_features(array_3d: np.ndarray) -> np.ndarray:\n",
    "    if array_3d.ndim != 3:\n",
    "        print(f\"Error: Input array must be 3-dimensional. Found {array_3d.ndim} dimensions.\")\n",
    "        return array_3d\n",
    "\n",
    "    N = array_3d.shape[0]\n",
    "    array_2d = array_3d.reshape(N, -1)\n",
    "    \n",
    "    return array_2d\n",
    "\n",
    "def reshape_to_3d(array_2d: np.ndarray, original_shape: tuple) -> np.ndarray:\n",
    "    if array_2d.shape[1] != original_shape[1] * original_shape[2]:\n",
    "        print(\"Error: Feature count mismatch. Cannot reshape back to original dimensions.\")\n",
    "        return array_2d\n",
    "    \n",
    "    feature_shape = original_shape[1:] \n",
    "    \n",
    "    N = array_2d.shape[0]\n",
    "    \n",
    "    array_3d = array_2d.reshape(N, *feature_shape)\n",
    "    \n",
    "    return array_3d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1db0acd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "no2_scaler=StandardScaler()\n",
    "o3_scaler=StandardScaler()\n",
    "\n",
    "no2=flatten_features(no2)\n",
    "no2_2024=flatten_features(no2_2024)\n",
    "no2_train_scaled=no2_scaler.fit_transform(no2)\n",
    "no2_test_scaled=no2_scaler.transform(no2_2024)\n",
    "\n",
    "o3=flatten_features(o3)\n",
    "o3_2024=flatten_features(o3_2024)\n",
    "o3_train_scaled=o3_scaler.fit_transform(o3)\n",
    "o3_test_scaled=o3_scaler.transform(o3_2024)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "13410866",
   "metadata": {},
   "outputs": [],
   "source": [
    "no2_train_scaled=reshape_to_3d(no2_train_scaled,[730,9,10])\n",
    "no2_test_scaled=reshape_to_3d(no2_test_scaled,[366,9,10])\n",
    "o3_train_scaled=reshape_to_3d(o3_train_scaled,[730,9,10])\n",
    "o3_test_scaled=reshape_to_3d(o3_test_scaled,[366,9,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a88f7f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./processed_data/no2_train.npy',no2_train_scaled)\n",
    "np.save('./processed_data/no2_test.npy',no2_test_scaled)\n",
    "np.save('./processed_data/o3_test.npy',o3_test_scaled)\n",
    "np.save('./processed_data/o3_train.npy',o3_train_scaled)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
