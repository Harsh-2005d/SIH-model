{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8970924",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train_st=np.load('./processed_data/station/train.npy')\n",
    "train_lab=np.load('./processed_data/labels/train_labels.npy')\n",
    "test_st=np.load('./processed_data/station/test.npy')\n",
    "test_lab=np.load('./processed_data/labels/test_labels.npy')\n",
    "no2_train_sat=np.load('./processed_data/no2_train.npy')\n",
    "o3_test_sat=np.load('./processed_data/o3_test.npy')\n",
    "no2_test_sat=np.load('./processed_data/no2_test.npy')\n",
    "o3_train_sat=np.load('./processed_data/o3_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2acf9583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17520, 16)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_st.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b6ac9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_standardize(x, mean=None, std=None):\n",
    "    \"\"\"\n",
    "    Apply log1p transform, then standardize.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : array-like\n",
    "        Input values (e.g., ozone concentrations).\n",
    "    mean : float, optional\n",
    "        Mean from training set. If None, computed from x.\n",
    "    std : float, optional\n",
    "        Std from training set. If None, computed from x.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    x_scaled : np.ndarray\n",
    "        Log-transformed + standardized values.\n",
    "    mean : float\n",
    "        Mean used for scaling (store this for test data).\n",
    "    std : float\n",
    "        Std used for scaling (store this for test data).\n",
    "    \"\"\"\n",
    "    x_log = np.log1p(x)\n",
    "    \n",
    "    if mean is None:\n",
    "        mean = x_log.mean()\n",
    "    if std is None:\n",
    "        std = x_log.std()\n",
    "        \n",
    "    \n",
    "    x_scaled = (x_log - mean) / std\n",
    "    return x_scaled, mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e7f56b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lab,train_mean,train_std=log_standardize(train_lab)\n",
    "test_lab,_,_=log_standardize(test_lab,train_mean,train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd10b1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17519, 20) (17519,)\n",
      "Random Forest Training Complete. Test set size: 8783\n",
      "=============================================\n",
      "R-squared (R²):                  0.7334\n",
      "Root Mean Squared Error (RMSE):  0.4748\n",
      "Mean Absolute Error (MAE):       0.3177\n",
      "Mean Absolute Percentage Error (MAPE): 152.84%\n",
      "=============================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "train_st=np.concatenate([train_st,train_lab],axis=1)\n",
    "test_st=np.concatenate([test_st,test_lab],axis=1)\n",
    "# Time-based split (assuming sequential data)\n",
    "X_train=train_st[:-1]\n",
    "y_train=train_lab[1:,1]\n",
    "print(X_train.shape,y_train.shape)\n",
    "X_test=test_st[:-1]\n",
    "y_test=test_lab[1:,1]\n",
    "# --- 2. Model Training ---\n",
    "rf_model = GradientBoostingRegressor(\n",
    "    n_estimators=100,      # Number of boosting stages\n",
    "    learning_rate=0.1,     # Shrinks the contribution of each tree\n",
    "    max_depth=3,           # Controls the size of the individual trees\n",
    "    random_state=42\n",
    ")\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# --- 3. Prediction and Evaluation ---\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Calculate Evaluation Metrics\n",
    "rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "# Simple MAPE function\n",
    "def calculate_mape(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_test - y_pred) / y_true)) * 100\n",
    "\n",
    "mape_rf = calculate_mape(y_test, y_pred_rf)\n",
    "\n",
    "# --- 4. Print Results ---\n",
    "print(f\"Random Forest Training Complete. Test set size: {len(X_test)}\")\n",
    "print(\"=\" * 45)\n",
    "print(f\"R-squared (R²):                  {r2_rf:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE):  {rmse_rf:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE):       {mae_rf:.4f}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape_rf:.2f}%\")\n",
    "print(\"=\" * 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e574aa4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Training Complete. Test set size: 17519\n",
      "=============================================\n",
      "R-squared (R²):                  0.8735\n",
      "Root Mean Squared Error (RMSE):  0.2546\n",
      "Mean Absolute Error (MAE):       0.1704\n",
      "Mean Absolute Percentage Error (MAPE): 107.29%\n",
      "=============================================\n"
     ]
    }
   ],
   "source": [
    "y_pred_rf = rf_model.predict(X_train)\n",
    "\n",
    "# Calculate Evaluation Metrics\n",
    "rmse_rf = np.sqrt(mean_squared_error(y_train, y_pred_rf))\n",
    "mae_rf = mean_absolute_error(y_train, y_pred_rf)\n",
    "r2_rf = r2_score(y_train, y_pred_rf)\n",
    "\n",
    "# Simple MAPE function\n",
    "def calculate_mape(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_train - y_pred) / y_true)) * 100\n",
    "\n",
    "mape_rf = calculate_mape(y_train, y_pred_rf)\n",
    "\n",
    "# --- 4. Print Results ---\n",
    "print(f\"Random Forest Training Complete. Test set size: {len(X_train)}\")\n",
    "print(\"=\" * 45)\n",
    "print(f\"R-squared (R²):                  {r2_rf:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE):  {rmse_rf:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE):       {mae_rf:.4f}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape_rf:.2f}%\")\n",
    "print(\"=\" * 45)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
